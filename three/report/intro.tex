This report contains the analysis of different multi-agent reinforcement learning algorithms. \\
The algorithms were tested in an $11\times11$ grid-world with one prey-agent and $n\in \{1,2,3,4\}$ predator-agents. The goal of the prey is to have the predators bump into each other, while the goal of the predators is to have one of them catch the prey. All agents learn, by receiving a reward of $10$ if their team wins, and a reward of $-10$ if their team loses. \\
Three model-free learning algorithms were compared: Independent Q-learning, Independent Sarsa and Minimax-Q \cite{Littman94markovgames}. Contrary to earlier implementations, the problem at hand considers an intelligent prey, that learns alongside the predators. The effect of the different algorithms, with different parameter settings (learning rate $\alpha$, discount factor $\gamma$, explore-rate $\epsilon$), on different numbers of learning agents was analyzed and the results reported in this paper.